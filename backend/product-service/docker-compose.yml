version: "3.9"

services:
  mongo:
    image: mongo:7
    container_name: mongo
    ports:
      - "27017:27017"
    healthcheck:
      test: [ "CMD", "mongosh", "--eval", "db.adminCommand('ping')" ]
      interval: 10s
      timeout: 5s
      retries: 5
    volumes:
      - mongo_data:/data/db
    networks:
      - product-net

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.15.3
    container_name: elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - ES_JAVA_OPTS=-Xms512m -Xmx512m
    ports:
      - "9200:9200"
    healthcheck:
      test: [ "CMD-SHELL", "curl -f http://localhost:9200 || exit 1" ]
      interval: 10s
      timeout: 5s
      retries: 5
    volumes:
      - es_data:/usr/share/elasticsearch/data
    networks:
      - product-net

  product-service:
    build: .
    container_name: product-service
    depends_on:
      - redis
      - mongo
      - elasticsearch
      - logstash
    environment:
      - CATEGORY_SERVICE_URL=http://category-service:8090/api/v1/categories
      - MONGO_URI=mongodb://mongo:27017/product_db
      - ELASTIC_URI=http://elasticsearch:9200
      - JWT_SECRET=supersecretkeythatshouldbereplacedandstoredsecurely
      - SERVER_PORT=8080
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - LOGSTASH_HOST=logstash
      - LOGSTASH_PORT=5000
    ports:
      - "8080:8080"
    networks:
      - product-net

  category-service:
    build: ../category-service
    container_name: category-service
    depends_on:
      - redis
      - mongo
      - elasticsearch
      - logstash
    environment:
      - PRODUCT_SERVICE_URL=http://product-service:8080/api/v1/product
      - MONGO_URI=mongodb://mongo:27017/product_db
      - ELASTIC_URI=http://elasticsearch:9200
      - JWT_SECRET=supersecretkeythatshouldbereplacedandstoredsecurely
      - SERVER_PORT=8090
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - LOGSTASH_HOST=logstash
      - LOGSTASH_PORT=5000
    ports:
      - "8090:8090"
    networks:
      - product-net

  redis:
    image: redis:7
    container_name: redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: [ "CMD", "redis-cli", "ping" ]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - product-net

  kibana:
    image: docker.elastic.co/kibana/kibana:8.15.3
    container_name: kibana
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    ports:
      - "5601:5601"
    depends_on:
      elasticsearch:
        condition: service_healthy
    healthcheck:
      test: [ "CMD-SHELL", "curl -f http://localhost:5601/api/status | grep '\"state\":\"green\"' || exit 1" ]
      interval: 30s
      timeout: 10s
      retries: 10
      start_period: 40s
    networks:
      - product-net

  logstash:
    image: docker.elastic.co/logstash/logstash:8.5.3
    container_name: logstash
    volumes:
      - ./logstash/pipeline:/usr/share/logstash/pipeline:ro
    ports:
      - "5000:5000"     # TCP input for app logs
      - "9600:9600"     # Logstash monitoring API
    depends_on:
      - elasticsearch
    networks:
      - product-net


  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
    networks:
      - product-net

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3000:3000"
    depends_on:
      - prometheus
    networks:
      - product-net

    # optional: filebeat alternative if you prefer shipping log files instead of TCP
  filebeat:
    image: docker.elastic.co/beats/filebeat:8.5.3
    container_name: filebeat
    user: root
    volumes:
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - ./filebeat/filebeat.yml:/usr/share/filebeat/filebeat.yml:ro
    depends_on:
      - logstash
    networks:
      - product-net

networks:
  product-net:

volumes:
  mongo_data:
  es_data:
  redis_data:
